{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26d0f56a-d467-40e9-b736-20dc3ad7b986",
   "metadata": {},
   "source": [
    "# Functions\n",
    "\n",
    "In this notebook, I'm creating all the functions that I later use in my analsis. I benefited from the tutorial provided in this [link](https://www.youtube.com/watch?v=3q80zPZyyyM&ab_channel=technologyCult)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed2a248-2ae6-4161-90ad-6d880b4afc3b",
   "metadata": {},
   "source": [
    "### Feature Engineering and Data Cleaning\n",
    "\n",
    "The function `clean_data` cleans tha ames data set and creates new features that may be used during the analysis step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa417a4f-ad2c-4d56-8654-f207f05bb71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting clean_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile clean_data.py\n",
    "   \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def create_infrequent_category(data, threshold, category_labels_dict={}):\n",
    "    cat_dict = {}\n",
    "    if category_labels_dict:\n",
    "        for col in data.columns:\n",
    "            data[col] = np.where(data[col].isin(category_labels_dict[col]), data[col], 'infrequent')\n",
    "        \n",
    "    else:\n",
    "        for col in data.columns:  \n",
    "            value_counts = data[col].value_counts()\n",
    "            low_freq_levels = value_counts[value_counts < threshold].index\n",
    "            data[col] = np.where(data[col].isin(low_freq_levels), 'infrequent', data[col])\n",
    "            var_labels = data[col].value_counts().index.tolist()\n",
    "            cat_dict[col]=var_labels\n",
    "    return data, cat_dict\n",
    "\n",
    "def clean_data(data, version, cat_labels={}):\n",
    "    \"\"\"\n",
    "    Cleans the given dataset based on the specified version.\n",
    "\n",
    "    Inputs:\n",
    "    - data: DataFrame containing the dataset to be cleaned.\n",
    "    - version: String indicating the version of cleaning to be applied ('0' or 'mean').\n",
    "\n",
    "    Returns:\n",
    "    - Cleaned DataFrame with missing values replaced according to the specified version.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    ames = data.copy()\n",
    "    \n",
    "    ames.columns = ames.columns.str.lower().str.replace(' ', '_')\n",
    "    ames.rename(columns={'id':'Id', 'saleprice':'SalePrice', 'year_remod/add':'year_remod', '2nd_flr_sf':'second_flr_sf', \n",
    "                         '1st_flr_sf':'first_flr_sf'}, inplace=True)\n",
    "\n",
    "    \n",
    "    ames['have_pool'] = np.where(ames['pool_qc'].isna(), 'No', 'Yes')\n",
    "    ames['have_misc_features'] = np.where(ames['misc_feature'].isna(), 'No', 'Yes')\n",
    "    ames['have_fence'] = np.where(ames['fence'].isna(), 'No', 'Yes')\n",
    "\n",
    "    ames['porch_sf'] = ames['open_porch_sf'] + ames['enclosed_porch'] +ames['3ssn_porch'] + ames['screen_porch']\n",
    "\n",
    "    for col in ['garage_area', 'total_bsmt_sf', 'bsmtfin_sf_1', 'bsmtfin_sf_2', 'mas_vnr_area', 'fireplaces', 'wood_deck_sf', 'porch_sf']:\n",
    "        ames[f'have_{col}'] = np.where(ames[col]==0, 'No', 'Yes') \n",
    "        \n",
    "            \n",
    "\n",
    "    for val in [1, 2, 3]:\n",
    "        ames[f'garage_cars_{val}'] = np.where(ames['garage_cars']==val, 'Yes', 'No') \n",
    "\n",
    "    ames['bsmtfin_type_2_unf'] = np.where(ames['bsmtfin_type_2'] == 'unf', 'Yes', 'No')\n",
    "\n",
    "\n",
    "    for col in ['alley', 'fence', 'fireplace_qu', 'garage_finish', 'garage_type', 'bsmt_exposure', 'bsmt_cond', 'bsmt_qual', \n",
    "                    'mas_vnr_type', 'bsmtfin_type_1', 'bsmtfin_type_2', 'electrical', 'garage_cond', 'garage_qual']:\n",
    "            ames[col].fillna('missing', inplace=True)\n",
    "            \n",
    "    number_words = {\n",
    "        1: 'one',\n",
    "        2: 'two',\n",
    "        3: 'three',\n",
    "        4: 'four',\n",
    "        5: 'five',\n",
    "        6: 'six',\n",
    "        7: 'seven',\n",
    "        8: 'eight',\n",
    "        9: 'nine',\n",
    "        10: 'ten'\n",
    "        }\n",
    "    \n",
    "    ames['overall_qual'] = ames['overall_qual'].map(number_words)\n",
    "    ames['overall_cond'] = ames['overall_cond'].map(number_words)\n",
    "\n",
    "    \n",
    "    ames['bsmt_total_bath'] =ames['bsmt_full_bath'] + 0.5 * ames['bsmt_half_bath'] \n",
    "\n",
    "    ames['total_bath'] = ames['full_bath'] + 0.5 * ames['half_bath']\n",
    "\n",
    "    ames['age'] = ames['yr_sold'] - ames['year_built']\n",
    "    ames['new_construction'] = np.where(ames['age'] < 5, 'Yes', 'No')\n",
    "\n",
    "    ames['age_by_remodel'] = ames['yr_sold'] - ames['year_remod']\n",
    "\n",
    "    ames['house_remodeled'] = np.where(ames['year_built'] == ames['year_remod'], 'No', 'Yes')\n",
    "    \n",
    "    ames['total_area_sf'] = ames['gr_liv_area'] + ames['total_bsmt_sf'] \n",
    "    \n",
    "    ames['total_area_sf_sq'] = ames['total_area_sf'] * ames['total_area_sf'] \n",
    "    # ames['gr_liv_area_squared'] = ames['gr_liv_area'] * ames['gr_liv_area']\n",
    "    ames['age_squared'] = ames['age'] * ames['age']\n",
    "    ames['age_by_remodel_squared'] = ames['age_by_remodel'] * ames['age_by_remodel']\n",
    "    # ames['totrms_abvgrd_squared'] = ames['totrms_abvgrd'] * ames['totrms_abvgrd']\n",
    "    ames['garage_area_X_garage_cars'] = ames['garage_area'] * ames['garage_cars']\n",
    "    # ames['gr_liv_area_X_total_bsmt_sf'] = ames['gr_liv_area'] * ames['total_bsmt_sf']\n",
    "    ames['gr_liv_area_X_garage_cars'] = ames['gr_liv_area'] * ames['garage_cars']\n",
    "    ames['gr_liv_area_X_total_bath'] = ames['gr_liv_area'] * ames['total_bath']\n",
    "    ames['gr_liv_area_X_bedroom_abvgr'] = ames['gr_liv_area'] * ames['bedroom_abvgr']\n",
    "    ames['bsmtfin_sf_1_squared'] = ames['bsmtfin_sf_1'] * ames['bsmtfin_sf_1']\n",
    "\n",
    "    \n",
    "    ames['overall_qual'] = ames['overall_qual'].astype('object')\n",
    "    ames['overall_cond'] = ames['overall_cond'].astype('object')\n",
    "\n",
    "    \n",
    "    numeric_col = ames.select_dtypes(include=['int64', 'float64']).isna().sum()\n",
    "    numeric_with_missing = numeric_col[numeric_col > 0].index\n",
    "\n",
    "    for col in numeric_with_missing:\n",
    "        if version == '0':\n",
    "            ames[col].fillna(0, inplace=True)\n",
    "        elif version == 'mean':\n",
    "            ames[col].fillna(ames[col].mean(), inplace=True)\n",
    "               \n",
    "    data, categorical_variable_label_dict = create_infrequent_category(ames.select_dtypes(include='object'), \n",
    "                                                                       threshold=20, \n",
    "                                                                       category_labels_dict=cat_labels)\n",
    "    \n",
    "    ames = pd.concat([ames.select_dtypes(include=['int64', 'float64']), data], axis=1)\n",
    "\n",
    "    ames.drop(\n",
    "        columns=['pid', 'pool_qc', 'misc_feature', 'garage_qual', 'bsmtfin_type_2', 'garage_yr_blt', 'garage_cond',\n",
    "                 'ms_subclass', 'street', 'utilities', 'condition_2', 'roof_matl', 'exterior_2nd', 'heating',\n",
    "                 'pool_area', 'misc_val', 'year_built', 'year_remod', 'bsmt_full_bath', \n",
    "                 'bsmt_half_bath', 'full_bath', 'half_bath'], inplace=True)\n",
    "\n",
    "    return ames, categorical_variable_label_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8d1056-a6ba-46cb-af75-71d10405f175",
   "metadata": {},
   "source": [
    "I learned the concept of raising value errors for improved error handling from this [link](https://www.digitalocean.com/community/tutorials/python-valueerror-exception-handling-examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "637c12ff-b383-40cb-ac75-f714da897dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting outlier_censoring.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile outlier_censoring.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def outlier_censoring(df, upper_limit=95):\n",
    "    \"\"\"\n",
    "    Caps the values of numeric features in a DataFrame to a specified upper limit percentile.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        upper_limit (float, optional): The percentile value to use as the upper limit. Defaults to 95.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with capped values for numeric features.\n",
    "    \"\"\"\n",
    "    if upper_limit <= 0 or upper_limit >= 100:\n",
    "        raise ValueError(\"The upper_limit parameter must be between 0 and 100.\")\n",
    "    \n",
    "    data = df.copy()\n",
    "    numeric_features = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "    \n",
    "    if len(numeric_features) == 0:\n",
    "        raise ValueError(\"No numeric features found in the DataFrame.\")\n",
    "    \n",
    "    for col in numeric_features:\n",
    "        percentile_value = np.percentile(data[col], upper_limit)\n",
    "        data.loc[data[col] > percentile_value, col] = percentile_value\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229c9bf4-18f0-4d36-9d9b-b60e5a1919d1",
   "metadata": {},
   "source": [
    "The commented code below was an interesting exercise to maintain a list of categories once the data is saved. Apparently, after reading the data and importing the cleaned data using Pandas, any columns with a data type of 'category' will be converted to 'object'. However, using the method below, it will be possible to convert the data type back to 'category'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aabe4f5a-2d5d-432a-bfc3-a8a0642a45d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## list of categories\n",
    "## https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas\n",
    "\n",
    "# pd.DataFrame(ames_train.select_dtypes(include='category').columns).to_csv('../datasets/category_list', index=False)\n",
    "# cat_name = pd.read_csv('../datasets/category_list')\n",
    "# cat_dict = {row['0']:'category' for index, row in cat_name.iterrows()}\n",
    "# ames = pd.read_csv('../datasets/ames_cleaned.csv',  dtype=cat_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
